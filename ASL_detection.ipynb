{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "print(os.listdir(\"../input/asl-alphabet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_dir = '../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train'\n",
    "test_dir = '../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_unique():\n",
    "    size_img = 64,64 \n",
    "    images_for_plot = []\n",
    "    labels_for_plot = []\n",
    "    for folder in os.listdir(train_dir):\n",
    "        for file in os.listdir(train_dir + '/' + folder):\n",
    "            filepath = train_dir + '/' + folder + '/' + file\n",
    "            image = cv2.imread(filepath)\n",
    "            final_img = cv2.resize(image, size_img)\n",
    "            final_img = cv2.cvtColor(final_img, cv2.COLOR_BGR2RGB)\n",
    "            images_for_plot.append(final_img)\n",
    "            labels_for_plot.append(folder)\n",
    "            break\n",
    "    return images_for_plot, labels_for_plot\n",
    "\n",
    "images_for_plot, labels_for_plot = load_unique()\n",
    "print(\"unique_labels = \", labels_for_plot)\n",
    "\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "def plot_images(fig, image, label, row, col, index):\n",
    "    fig.add_subplot(row, col, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "    plt.title(label)\n",
    "    return\n",
    "\n",
    "image_index = 0\n",
    "row = 5\n",
    "col = 6\n",
    "for i in range(1,(row*col)):\n",
    "    plot_images(fig, images_for_plot[image_index], labels_for_plot[image_index], row, col, i)\n",
    "    image_index = image_index + 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,\n",
    "                   'N':13,'O':14,'P':15,'Q':16,'R':17,'S':18,'T':19,'U':20,'V':21,'W':22,'X':23,'Y':24,\n",
    "                   'Z':25,'space':26,'del':27,'nothing':28}\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Loads data and preprocess. Returns train and test data along with labels.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    size = 64,64\n",
    "    print(\"LOADING DATA FROM : \",end = \"\")\n",
    "    for folder in os.listdir(train_dir):\n",
    "        print(folder, end = ' | ')\n",
    "        for image in os.listdir(train_dir + \"/\" + folder):\n",
    "            temp_img = cv2.imread(train_dir + '/' + folder + '/' + image)\n",
    "            temp_img = cv2.resize(temp_img, size)\n",
    "            images.append(temp_img)\n",
    "            labels.append(labels_dict[folder])\n",
    "    \n",
    "    images = np.array(images)\n",
    "    images = images.astype('float32')/255.0\n",
    "    \n",
    "    labels = keras.utils.to_categorical(labels)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size = 0.05)\n",
    "    \n",
    "    print()\n",
    "    print('Loaded', len(X_train),'images for training,','Train data shape =',X_train.shape)\n",
    "    print('Loaded', len(X_test),'images for testing','Test data shape =',X_test.shape)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, kernel_size = [3,3], padding = 'same', activation = 'relu', input_shape = (64,64,3)))\n",
    "    model.add(Conv2D(32, kernel_size = [3,3], padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPool2D(pool_size = [3,3]))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size = [3,3], padding = 'same', activation = 'relu'))\n",
    "    model.add(Conv2D(64, kernel_size = [3,3], padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPool2D(pool_size = [3,3]))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size = [3,3], padding = 'same', activation = 'relu'))\n",
    "    model.add(Conv2D(256, kernel_size = [3,3], padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPool2D(pool_size = [3,3]))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation = 'relu', kernel_regularizer = regularizers.l2(0.001)))\n",
    "    model.add(Dense(29, activation = 'softmax'))\n",
    "    \n",
    "    model.compile(optimizer = 'adam', loss = keras.losses.categorical_crossentropy, metrics = [\"accuracy\"])\n",
    "    \n",
    "    print(\"MODEL CREATED\")\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def fit_model(X_train,Y_train):\n",
    "    model_hist = model.fit(X_train, Y_train, batch_size = 64, epochs = 5, validation_split = 0.1)\n",
    "    return model_hist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "X_train, X_test, Y_train, Y_test=load_data()\n",
    "curr_model_hist = fit_model(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(curr_model_hist.history['accuracy'])\n",
    "plt.plot(curr_model_hist.history['val_accuracy'])\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.title('accuracy plot - train vs validation')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(curr_model_hist.history['loss'])\n",
    "plt.plot(curr_model_hist.history['val_loss'])\n",
    "plt.legend(['training loss', 'validation loss'], loc = 'upper right')\n",
    "plt.title('loss plot - training vs vaidation')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_metrics = model.evaluate(X_test, Y_test)\n",
    "print(\"\\nEvaluation Accuracy = \", \"{:.2f}%\".format(evaluate_metrics[1]*100),\"\\nEvaluation loss = \" ,\"{:.6f}\".format(evaluate_metrics[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    images = []\n",
    "    names = []\n",
    "    size = 64,64\n",
    "    for image in os.listdir(test_dir):\n",
    "        temp = cv2.imread(test_dir + '/' + image)\n",
    "        temp = cv2.resize(temp, size)\n",
    "        images.append(temp)\n",
    "        names.append(image)\n",
    "    images = np.array(images)\n",
    "    images = images.astype('float32')/255.0\n",
    "    return images, names\n",
    "\n",
    "test_images, test_img_names = load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on an image and append it to the list (predictions).\n",
    "predictions = [model.predict_classes(image.reshape(1,64,64,3))[0] for image in test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_for_plot(predictions):\n",
    "    predictions_labels = []\n",
    "    for i in range(len(predictions)):\n",
    "        for ins in labels_dict:\n",
    "            if predictions[i] == labels_dict[ins]:\n",
    "                predictions_labels.append(ins)\n",
    "                break\n",
    "    return predictions_labels\n",
    "\n",
    "predictions_labels_plot = get_labels_for_plot(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predfigure = plt.figure(figsize = (13,13))\n",
    "def plot_image_1(fig, image, label, prediction, predictions_label, row, col, index):\n",
    "    fig.add_subplot(row, col, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "    title = \"prediction : [\" + str(predictions_label) + \"] \"+ \"\\n\" + label\n",
    "    plt.title(title)\n",
    "    return\n",
    "\n",
    "image_index = 0\n",
    "row = 5\n",
    "col = 6\n",
    "for i in range(1,(row*col-1)):\n",
    "    plot_image_1(predfigure, test_images[image_index], test_img_names[image_index], predictions[image_index], predictions_labels_plot[image_index], row, col, i)\n",
    "    image_index = image_index + 1\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
